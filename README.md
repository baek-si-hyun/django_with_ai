<br>
<br>
<br>

![logo-lettering](https://github.com/DianaKang0123/selleaf/assets/156397873/b5f4c8cd-6d88-4965-9336-ad89f151ba52)
<br>
<br>
<br>

# ë¨¸ì‹ ëŸ¬ë‹ ì›¹ ì ìš© í”„ë¡œì íŠ¸
<br>
<br>
<br>

![image-6](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/b2d7bb2c-4d6b-45bf-8f84-79c22a49c199)

<br>

##  ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ í…ìŠ¤íŠ¸ ë¶„ë¥˜ë¥¼ í†µí•œ ë¹„ì†ì–´ ê°ì§€ ì‹œìŠ¤í…œ

### **0ï¸âƒ£ ëª©ì°¨**

1. ê°œìš”
2. ë°ì´í„° ìˆ˜ì§‘
3. ë°ì´í„° ì „ì²˜ë¦¬ 
4. ë¹„ì†ì–´ ê°ì§€ ì•Œê³ ë¦¬ì¦˜ì˜ íë¦„ 
5. ê²°ê³¼

<br>

---
<br>

### **1ï¸âƒ£ ê°œìš”**

<br>

ì…€ë¦¬í”„ëŠ” ì»¤ë®¤ë‹ˆí‹° ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ììœ ë¡­ê²Œ ê²Œì‹œê¸€ì„ ì˜¬ë¦´ìˆ˜ ìˆê³  í•´ë‹¹ ê²Œì‹œë¬¼ì— ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ í…ìŠ¤íŠ¸ ë¶„ë¥˜ë¥¼ í†µí•œ ë¹„ì†ì–´ ê°ì§€ ì‹œìŠ¤í…œ**ì€ ì¼ë°˜ ê²Œì‹œë¬¼ì˜ ëŒ“ê¸€ì— ì ìš©ë˜ë©°, **ì¼ë°˜ ê²Œì‹œê¸€ ëŒ“ê¸€ ì‘ì„±** ë‹¨ê³„ì—ì„œ ìœ ì €ê°€ ì‘ì„±í•˜ëŠ” ëŒ“ê¸€ì˜ ë‚´ìš©ì„ ë‹¨ì–´ë¡œ ë¶„í• í•˜ì—¬ ë²¡í„°í™” ì‹œí‚¤ê³  ë°±í„°í™”ëœ ë°ì´í„°ë¥¼ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸°ì— ì…ë ¥í•˜ì—¬ ë¹„ì†ì–´ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì˜ˆì¸¡ ê²°ê³¼ì— ë”°ë¼ ëŒ“ê¸€ì— ë¹„ì†ì–´ë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤.

<br>

---

<br>

### **2ï¸âƒ£ ë°ì´í„° ìˆ˜ì§‘**
<br>

#### ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.   

1. í¬ë¡¤ë§ì„ í†µí•œ ëŒ“ê¸€ ë°ì´í„° ìˆ˜ì§‘
- í¬ë¡¤ë§ì„ í†µí•˜ì—¬ ëŒ“ê¸€ì„ ìˆ˜ì§‘í•˜ê³  ë¹„ì†ì–´ê°€ í¬í•¨ëœ ëŒ“ê¸€ê³¼ í¬í•¨ë˜ì§€ ì•Šì€ ëŒ“ê¸€ì˜ ë¹„ì¤‘ì„ ë§ì¶°ì£¼ê¸° ìœ„í•´ ì „ì²´ ëŒ“ê¸€ ë°ì´í„°ì˜ 45%ë¥¼ ì„ì˜ë¡œ ìš•ì„¤ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

    <details>
    <summary>í¬ë¡¤ë§ ë¡œì§</summary>

    ```
    if __name__ == '__main__':
        warnings.filterwarnings('ignore')

        if os.path.exists('comments.csv'):
            existing_df = pd.read_csv('comments.csv', encoding='utf-8-sig', index_col=0)
            comment_final = existing_df['Comment'].tolist()
        else:
            existing_df = pd.DataFrame()
            comment_final = []

        driver = webdriver.Chrome()
        driver.get("https://www.youtube.com/watch?v=t7w3k3pjZY4")
        driver.implicitly_wait(3)

        time.sleep(1.5)

        driver.execute_script("window.scrollTo(0, 800)")
        time.sleep(3)

        last_height = driver.execute_script("return document.documentElement.scrollHeight")

        while True:
            driver.execute_script("window.scrollTo(0, document.documentElement.scrollHeight);")
            time.sleep(2)

            new_height = driver.execute_script("return document.documentElement.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

        time.sleep(1.5)

        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')

        comment_list = soup.select("span.yt-core-attributed-string")

        for i in range(len(comment_list)):
            temp_comment = comment_list[i].text.replace('"', '')
            temp_comment = temp_comment.replace('\n', ' ')
            temp_comment = temp_comment.strip()
            comment_final.append(temp_comment)
        new_df = pd.DataFrame({'Comment': comment_final})

        combined_df = pd.concat([existing_df, new_df]).drop_duplicates().reset_index(drop=True)

        combined_df.to_csv('qweqwe.csv', index=True, encoding='utf-8-sig')

        driver.quit()
    ```

    </details>
    <br>
    <details>
    <summary>ì„ì˜ë¡œ ìš•ì„¤ì„ ì¶”ê°€í•˜ëŠ” ì½”ë“œ</summary>

    ```
    profanity_list = ['ìš•ì„¤ ë¦¬ìŠ¤íŠ¸']

    def add_random_profanity(comment):
        new_comment = ''
        for word in comment.split():
            new_comment += word + ' '
            if random.random() < 0.4:
                profanity = random.choice(profanity_list)
                if random.random() < 0.5:
                    new_comment += profanity + ' '
                else:
                    new_comment += profanity
        return new_comment.strip()

    co_df = pd.read_csv('comments.csv')

    co_df['Comment'] = co_df['Comment'].apply(add_random_profanity)
    ```

    </details> 
    <br>
    <details>
    <summary>ì¶”ê°€í•œ ìš•ì„¤ì´ ìˆìœ¼ë©´ Target ì¹¼ëŸ¼ì— 1 ì—†ìœ¼ë©´ 0 ê°’ ë„£ì–´ì£¼ê¸°</summary>

    ```
        profanity_list = ['ìš•ì„¤ ë¦¬ìŠ¤íŠ¸']

        profanity_list = [word.replace(' ', '') for word in profanity_list]

        co_df['Profanity'] = co_df['Comment'].apply(lambda x: 1 if any(word in x for word in profanity_list) else 0)
    ```

    </details> 
<br>

2. ì§ì ‘ ëŒ“ê¸€ ë°ì´í„° ì„¸íŠ¸ ìˆ˜ì§‘
- ã…£ã…£ã…£ã…£ã…£ã…£

    <details>
    <summary></summary>

    ```

    ```

    </details>
<br>

3. ë‘ ë°ì´í„° ì„¸íŠ¸ í•©ì¹˜ê¸°
- ìˆ˜ì§‘í•œ ë‘ ë°ì´í„° ì„¸íŠ¸ë¥¼ í•©ì¹˜ê³  ê²°ê³¼ë¥¼ csvíŒŒì¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.

    <details>
    <summary>ë‘ ë°ì´í„° ì„¸íŠ¸ë¥¼ í•©ì¹˜ëŠ” ì½”ë“œ</summary>

    ```
        df_combined = pd.concat([co_df, bw_df], ignore_index=True)
    ```

    </details>
    <br>
    <details>
    <summary>ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ëŠ” ì½”ë“œ</summary>

    ```
        df_combined.to_csv('merge_comments_data.csv', index=False, encoding='utf-8-sig')
    ```

    </details>
<br>
---
<br>


### **3ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬**
<br>

#### ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. ë‹¨ì–´ë³„ë¡œ ë¶„í• í•˜ì—¬ í•™ìŠµí•˜ëŠ” ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸°ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ë¶ˆìš©ì–´ë¥¼ ì œê±°í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ í•œê¸€, ì˜ì–´ì— ëŒ€í•œ ë¹„ì†ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ í•œê¸€, ì˜ì–´, ìˆ«ìë¥¼ ì œì™¸í•œ íŠ¹ìˆ˜ë¬¸ì, ì´ëª¨í‹°ì½˜, íƒ€ ì–¸ì–´ë¥¼ ì œê±°í•˜ì˜€ìŠµë‹ˆë‹¤.
    <details>
    <summary>í•œê¸€, ì˜ì–´, ìˆ«ìë¥¼ ì œì™¸í•œ ë¬¸ìë“¤ì„ ì œê±°í•˜ëŠ” ì½”ë“œ</summary>

    ```
        korean_stopwords = set([
            'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ë“¤', 'ì˜', 'ë¥¼', 'ì€', 'ëŠ”', 'ì—', 'ì™€', 'ê³¼', 'ë„', 'ìœ¼ë¡œ', 'ê¹Œì§€', 'ë¶€í„°', 'ë‹¤ì‹œ', 'ë²ˆ', 'ë§Œ', 'í• ', 'í•œë‹¤', 'ê·¸ë¦¬ê³ '
        ])

        # ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
        def preprocess_text(text):
            # íŠ¹ìˆ˜ ë¬¸ì ì œê±°
            text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s-]', '', text)
            text = re.sub(r'\s+', ' ', text).strip()
            # í˜•íƒœì†Œ ë¶„ì„
            words = text.split()
            # ë¶ˆìš©ì–´ ì œê±°
            text = ' '.join([word for word in words if word not in korean_stopwords])
            return text

        # ë°ì´í„° ì „ì²˜ë¦¬ ì ìš©
        reply_df['Comment'] = reply_df['Comment'].apply(preprocess_text)
        reply_df['Comment'].replace('', pd.NA, inplace=True)
        reply_df.dropna(subset=['Comment'], inplace=True)

    ```

    </details>
    <br>

2. ì¤‘ë³µê³¼ nullì¸ ê°’ì„ í™•ì¸í•˜ê³  ì œê±°í•˜ì˜€ìŠµë‹ˆë‹¤.
    <details>
    <summary>ì¤‘ë³µê³¼ nullê°’ ì¡´ì¬ í™•ì¸ ë° ì œê±°í•˜ëŠ” ì½”ë“œ</summary>

    ```
    print(reply_df.duplicated().sum())
    reply_df.drop_duplicates(inplace=True)

    display(reply_df[reply_df['Comment'].isna()])
    reply_df = reply_df.dropna(subset=['Comment'])
    ```

    </details>

    <br>

3. microë°©ì‹ìœ¼ë¡œ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 scoreë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ Target ë°ì´í„°ì˜ ë¹„ì¤‘ì„ ë§ì·„ìŠµë‹ˆë‹¤. !!!!!!!!!!ì–¸ë” ìƒ˜í”Œë§í•œ ì´ìœ  ì ê¸°!!!!!!!!!!!!!!!!!!!!!
    <details>
    <summary>Target ë¹„ì¤‘ì„ í™•ì¸í•˜ê³  ì–¸ë” ìƒ˜í”Œë§í•˜ëŠ” ì½”ë“œ</summary>

    ```
        print(reply_df.Target.value_counts())

        profanity = reply_df[reply_df['Target'] == 1].sample(8151, random_state=124)
        normal = reply_df[reply_df['Target'] == 0]
        reply_df = pd.concat([profanity, normal]).reset_index(drop=True)
    ```

    </details>
    <br>
<br>

---
<br>

### **3ï¸âƒ£ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ : ëŒ“ê¸€ ì…ë ¥ì‹œ ìš•ì„¤ ë¶„ì„(ë‹¨ë³€ëŸ‰ ë¶„ì„)**


#### ëŒ“ê¸€ ì…ë ¥ì‹œ ìš•ì„¤ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. í™”ë©´ì—ì„œ ì…ë ¥ëœ ëŒ“ê¸€ì„ post-module.jsì˜ write í•¨ìˆ˜ì—ì„œ fatch ë¥¼ í†µí•´ post ë°©ì‹ìœ¼ë¡œ ì „ë‹¬
    <details>
    <summary>write í•¨ìˆ˜ ì½”ë“œ</summary>

    ```
        const write = async (reply) => {
            const response = await fetch("/post/replies/write/", {
                method: "POST",
                headers: {
                    'Content-Type': 'application/json;charset=utf-8',
                    'X-CSRFToken': csrf_token
                },
                body: JSON.stringify(reply)
            });
            return response.json()
        }
    ```

    </details>

<br>



2. view ì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ë¡œ ë¹„ì†ì–´ ê²€ì‚¬
    <details>
    <summary>ì „ë‹¬ ë°›ì€ ëŒ“ê¸€ ë‚´ìš© ë¹„ì†ì–´ ê²€ì‚¬ ì½”ë“œ</summary>

    ```
        class PostReplyWriteApi(APIView):
            @transaction.atomic
            def post(self, request):
                data = request.data
                post = Post.objects.filter(id=data['post_id']).values('member_id')

                new_sentence = [data['reply_content']]

                prediction = profanityDetectionPredict(new_sentence)
    ```

    </details>
    <br> 
    <details>
    <summary>ëª¨ë“ˆí™”ëœ ë¹„ì†ì–´ ê²€ì‚¬ ì½”ë“œ</summary>

    ```
        model_path = os.path.join(Path(__file__).resolve()\
            .parent, '../../ai/ai/commentai.pkl')


        def profanityDetectionPredict(new_sentence):
            loaded_model = joblib.load(model_path)

            prediction = loaded_model.predict(new_sentence)
            return prediction
    ```

    </details>

<br> 

3. ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì–´ ìˆì„ ì•Šì„ ê²½ìš°(prediction[0]ê°€ 0ì¼ ê²½ìš°) í•´ë‹¹ ê²Œì‹œë¬¼ì— ëŒ“ê¸€ì´ ì¶”ê°€ë˜ëŠ” ì½”ë“œ
    <details>
    <summary>ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì½”ë“œ</summary>

    ```
        message = 'fails'
            if prediction[0] == 0:
                message = 'ok'

                data = {
                    'post_reply_content': new_sentence[0],
                    'post_id': data['post_id'],
                    'member_id': request.session.get('member')['id']
                }

                PostReply.objects.create(**data)
    ```

    </details>

<br> 

4. ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì–´ ìˆì„ ê²½ìš° í•´ë‹¹ ëŒ“ê¸€ë¡œ ëª¨ë¸ì˜ ì¶”ê°€í•™ìŠµì„ ì§„í–‰í•˜ê³  í›ˆë ¨ ì „ìš© í…Œì´ë¸”ì— ì¶”ê°€í•˜ëŠ” ì½”ë“œ
    <details>
    <summary>ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì–´ìˆì„ ê²½ìš° ì¶”ê°€í•™ìŠµ ì‹œí‚¤ëŠ” ì½”ë“œ</summary>

    ```
            else:
                data = {
                    'comment': new_sentence[0],
                    'target': 1,
                }

                profanityDetectionModel(new_sentence)

                AiPostReply.objects.create(**data)

            return Response(message)
    ```

    </details>
    <br>    
    <details>
    <summary>ëª¨ë“ˆí™”ëœ ì¶”ê°€í•™ìŠµ ì‹œí‚¤ëŠ” ì½”ë“œ</summary>

    ```
        model_path = os.path.join(Path(__file__).resolve()\
            .parent, '../../ai/ai/commentai.pkl')

        def profanityDetectionModel(new_sentence):
            loaded_model = joblib.load(model_path)
            transformed_X_train = loaded_model.named_steps['count_vectorizer']\
                .transform(new_sentence)
            loaded_model.named_steps['multinomial_NB']\
                .partial_fit(transformed_X_train, [1])
            joblib.dump(loaded_model, model_path)
    ```

    </details>

<br>

---
<br>

### **3ï¸âƒ£ ë¬¸ì œ ëŒ“ê¸€ ì‹ ê³  ì‹œ ì‹¤ì‹œê°„ í•™ìŠµ**


#### ëŒ“ê¸€ ì‹ ê³ ì‹œ ìš•ì„¤ ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. ì‹ ê³ ëœ ëŒ“ê¸€ì„ ì²˜ë¦¬í•˜ëŠ” viewì—ì„œ ì‹ ê³ ë°›ì€ ëŒ“ê¸€ì„ ì¼ë°˜ ê²Œì‹œë¬¼ ëŒ“ê¸€ ì‹ ê³  í…Œì´ë¸”ì— ì¶”ê°€
    <details>
    <summary>ì¼ë°˜ ê²Œì‹œë¬¼ ëŒ“ê¸€ ì‹ ê³  í…Œì´ë¸”ì— ì¶”ê°€ ì½”ë“œ</summary>

    ```
        class PostReplyReportView(View):
            def post(self, request):
                data = request.POST
                member = request.session.get('member')['id']
                member_id = member.get('id')
                post_id = request.GET['id']
                reply_id = data['reply-report-reply-id']

                datas = {
                    'member_id': member_id,
                    'post_reply_id': reply_id,
                    'report_content': data['reply-report-content']
                }

                PostReplyReport.object.create(**datas)

                return redirect(f'/post/detail/?id={post_id}')
    ```

    </details>

<br>



2. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ì‹ ê³ ëœ ëŒ“ê¸€ì„ í™•ì¸í•˜ê³  ì‹ ê³ ë‹¹í•œ ëŒ“ê¸€ì„ ì‚­ì œ ì²˜ë¦¬í•˜ëŠ” viewì—ì„œ ì‚­ì œí•˜ê¸°ì „ í•´ë‹¹ ìš•ì„¤ ëŒ“ê¸€ë¡œ ëª¨ë¸ì„ ì¶”ê°€í•™ìŠµì„ ì§„í–‰, ì¼ë°˜ ëŒ“ê¸€ í…Œì´ë¸”ì—ì„œ ì‚­ì œí•˜ê³  ëª¨ë¸ í›ˆë ¨ í…Œì´ë¸”ì— ì¶”ê°€ 
    <details>
    <summary>ì‚­ì œí•˜ê¸°ì „ í•´ë‹¹ ìš•ì„¤ ëŒ“ê¸€ë¡œ ëª¨ë¸ì„ ì¶”ê°€í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ì½”ë“œ</summary>

    ```
        def delete(self, request, report_ids):
            report_ids = report_ids.split(',')

            for report_id in report_ids:
                if report_id != '':
                    post_report_reply = PostReplyReport.object.filter(id=report_id)\
                        .values().first()
                    report_reply_id = post_report_reply.get('post_reply_id')
                    post_reply = PostReply.objects.filter(id=report_reply_id)\
                        .values().first()

                    new_sentence = [post_reply['post_reply_content']]
                    profanityDetectionModel(new_sentence)

    ```

    </details>
    <br> 
    <details>
    <summary>ì¼ë°˜ ëŒ“ê¸€ í…Œì´ë¸”ì—ì„œ ì‚­ì œí•˜ê³  ëª¨ë¸ í›ˆë ¨ í…Œì´ë¸”ì— ì¶”ê°€í•˜ëŠ” ì½”ë“œ</summary>

    ```
                    data = {
                        'comment': new_sentence[0],
                        'target': 1,
                    }
                    AiPostReply.objects.create(**data)

                    PostReplyReport.object.get(id=report_id).delete()
                    PostReply.objects.get(id=report_reply_id).delete()
    ```

    </details>

<br>

---
<br>

### **4ï¸âƒ£ ìš•ì„¤ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ íë¦„**

<br>

#### ìš•ì„¤ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ì˜ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. í™”ë©´ì—ì„œ ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ” ëŒ“ê¸€ ì…ë ¥

    > ![image](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/e971451c-f718-4bcf-9b16-86e6b6713036)


2. ì…ë ¥ í´ë¦­ì‹œ post-module.jsì´ writeë¥¼ í†µí•˜ì—¬ í•´ë‹¹ ì •ë³´ post ë°©ì‹ìœ¼ë¡œ viewì— ì „ë‹¬
3. viewì—ì„œ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì„ í†µí•´ ë¹„ì†ì–´ í¬í•¨ ìœ ë¬´ë¥¼ ê²€ì‚¬í•˜ê³  ê²°ê³¼ë¥¼ return (ë¹„ì†ì–´ê°€ í¬í•¨ëœ ê²½ìš° ì¶”ê°€í•™ìŠµí›„ return)
4. returnëœ ê°’ì„ post-moduleì—ì„œ writeí•¨ìˆ˜ì˜ fetchë¥¼ í†µí•´ responseë¡œ return
5. returnìœ¼ë¡œ ì „ë‹¬ë°›ì€ response ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ 'ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤' ë¬¸êµ¬ í™”ë©´ì— ì¶œë ¥

    > ![image-3](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/24face29-414c-4474-bd27-db0fbbffaac3)


6. ë¹„ì†ì–´ê°€ í¬í•¨í•˜ì—¬ ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì‚¬ìš©ìëŠ” ì •ìƒì ì¸ ëŒ“ê¸€ì„ ì…ë ¥í•˜ê²Œ ë¨
7. ë¹„ì†ì–´ë¥¼ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì´ ê°ì§€í•˜ì§€ ëª»í•  ê²½ìš° ì‹ ê³  ê¸°ëŠ¥ì„ í†µí•´ ê´€ë¦¬ìì—ê²Œ ë¹„ì†ì–´ ëŒ“ê¸€ì´ ìˆìŒì„ ì•Œë¦¼

    > ![image-3](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/7314b731-49b4-480c-8b46-75560aaaaedb)

8. ê´€ë¦¬ìê°€ í•´ë‹¹ ì‹ ê³ ë¥¼ í™•ì¸í•˜ê³  ë¹„ì†ì–´ ëŒ“ê¸€ì„ ì‚­ì œì‹œ ì¶”ê°€í•™ìŠµ ì§„í–‰í›„ ì‚­ì œì²˜ë¦¬ (ëª¨ë¸ í›ˆë ¨ í…Œì´ë¸”ì—ëŠ” ì¶”ê°€)

    > ![image-3](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/74dd3564-d68b-42ff-90cd-d2595dd3f2df)

9. ê°ì§€í•˜ì§€ ëª»í•œ ë¹„ì†ì–´ë¥¼ í•™ìŠµí•¨ìœ¼ë¡œ ëª¨ë¸ì˜ ë¹„ì†ì–´ ê°ì§€ ëŠ¥ë ¥ í–¥ìƒ

---
<br>

### **5ï¸âƒ£ ê²°ê³¼**

<br>

> #### ğŸš© ë¹„ì†ì–´ ëŒ“ê¸€
> 
> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/24face29-414c-4474-bd27-db0fbbffaac3" width="600px">


> #### ğŸš© ë¹„ì†ì–´ ëŒ“ê¸€ ì‹ ê³ 
> 
> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/7314b731-49b4-480c-8b46-75560aaaaedb" width="300px">

> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/06149d04-cc85-4d48-8a88-06881b3f0b63" width="300px">
> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/74dd3564-d68b-42ff-90cd-d2595dd3f2df" width="500px">
> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/d98c7474-1837-418a-af16-d2814ab48d18" width="500px">

---
<br>

### **5ï¸âƒ£ íŠ¸ëŸ¬ë¸” ìŠˆíŒ…**

<br>

#### 1. ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ì´ ëª¨ë“  ë‹¨ì–´ë¥¼ ëª¨ë‘ ìš•ì„¤ì´ë¼ê³  ì˜ˆì¸¡
â— ë¬¸ì œ
1. ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ ì ìš©í•˜ì—¬ ë¹„ì†ì–´ ëŒ“ê¸€ ì§ì ‘ ì…ë ¥ í…ŒìŠ¤íŠ¸
2. ëª¨ë¸ì´ ì–´ë–¤ ë‹¨ì–´ë¥¼ ì…ë ¥ ë°›ì•„ë„ ëª¨ë‘ ë¹„ì†ì–´ê°€ í¬í•¨ ë˜ì–´ìˆë‹¤ê³  ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œ ë°œìƒ

â“ ì›ì¸
- <code>.fit</code>ì€ ì „ì²´ ë°ì´í„°ë¥¼ í•œë²ˆì— í•™ìŠµ ì‹œí‚¤ëŠ” ë©”ì„œë“œì´ë‹¤. <code>.fit</code>ì„ ì‚¬ìš©í•´ í›ˆë ¨ì„ ì‚¬ì „ì— ì§„í–‰í•œ ìƒíƒœì˜€ë‹¤.
- í™”ë©´ì—ì„œ ì „ë‹¬ ë°›ì€ ë¬¸ì¥ í•˜ë‚˜ë¡œ ì´ë¯¸ í›ˆë ¨ëœ ëª¨ë¸ì— ì „ì²´ ë°ì´í„° í•™ìŠµì„ ì§„í–‰ ì‹œì¼°ë‹¤.
- ê¸°ì¡´ì— ì‚¬ì „ í›ˆë ¨ë°›ì€ ëª¨ë¸ì˜ ë°ì´í„°ëŠ” ë‹¤ ì‚¬ë¼ì§€ê³  ì „ë‹¬ ë°›ì€ ë¬¸ì¥ ë°ì´í„° í•˜ë‚˜ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì´ ë˜ì—ˆë‹¤.
 
âœ” í•´ê²°
- ì „ì²´ ë°ì´í„°ë¥¼ í•™ìŠµ ì‹œí‚¤ëŠ” <code>.fit</code> ì‚¬ìš©í•˜ì§€ ì•Šê³  ê¸°ì¡´ì— í›ˆë ¨ë˜ì–´ ìˆëŠ” ëª¨ë¸ì— ì¶”ê°€ë¡œ í•™ìŠµì„ ì§„í–‰ì‹œí‚¤ëŠ” <code>.partial_fit</code> ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.

#### 2. ë„ˆë¬´ ë‚®ì€ ì •í™•ë„ë¡œ ì¸í•œ ë¹„ì†ì–´ ì˜ˆì¸¡ ë¬´ì˜ë¯¸
â— ë¬¸ì œ
1. 
2. 

â“ ì›ì¸
- 
 
âœ” í•´ê²°
-  

