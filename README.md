<br>
<br>
<br>

![logo-lettering](https://github.com/DianaKang0123/selleaf/assets/156397873/b5f4c8cd-6d88-4965-9336-ad89f151ba52)
<br>
<br>
<br>

# ë¨¸ì‹ ëŸ¬ë‹ ì›¹ ì ìš© í”„ë¡œì íŠ¸

<br>
<br>
<br>

![image-6](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/b2d7bb2c-4d6b-45bf-8f84-79c22a49c199)

<br>

## ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ í…ìŠ¤íŠ¸ ë¶„ë¥˜ë¥¼ í†µí•œ ë¹„ì†ì–´ ê°ì§€ ì‹œìŠ¤í…œ

### **0ï¸âƒ£ ëª©ì°¨**

1. ê°œìš”
2. ë°ì´í„° ìˆ˜ì§‘
3. ë°ì´í„° ì „ì²˜ë¦¬
4. ëŒ“ê¸€ ì…ë ¥ì‹œ ìš•ì„¤ ë¶„ì„
5. ë¬¸ì œ ëŒ“ê¸€ ì‹ ê³  ì‹œ ì‹¤ì‹œê°„ í•™ìŠµ
6. ìš•ì„¤ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ íë¦„
7. ê²°ê³¼
8. íŠ¸ëŸ¬ë¸” ìŠˆíŒ…
9. ëŠë‚€ì 

<br>

---

<br>

### **1ï¸âƒ£ ê°œìš”**

<br>

#### ì…€ë¦¬í”„ëŠ” ì»¤ë®¤ë‹ˆí‹° ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. 
ììœ ë¡­ê²Œ ê²Œì‹œê¸€ì„ ì˜¬ë¦´ìˆ˜ ìˆê³  í•´ë‹¹ ê²Œì‹œë¬¼ì— ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> **ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ í…ìŠ¤íŠ¸ ë¶„ë¥˜ë¥¼ í†µí•œ ë¹„ì†ì–´ ê°ì§€ ì‹œìŠ¤í…œ**ì€ ì¼ë°˜ ê²Œì‹œë¬¼ì˜ ëŒ“ê¸€ì— ì ìš©ë˜ë©°, **ì¼ë°˜ ê²Œì‹œê¸€ ëŒ“ê¸€ ì‘ì„±** ë‹¨ê³„ì—ì„œ ìœ ì €ê°€ ì‘ì„±í•˜ëŠ” ëŒ“ê¸€ì˜ ë‚´ìš©ì„ ë‹¨ì–´ë¡œ ë¶„í• í•˜ì—¬ ë²¡í„°í™” ì‹œí‚¤ê³  ë°±í„°í™”ëœ ë°ì´í„°ë¥¼ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸°ì— ì…ë ¥í•˜ì—¬ ë¹„ì†ì–´ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì˜ˆì¸¡ ê²°ê³¼ì— ë”°ë¼ ëŒ“ê¸€ì— ë¹„ì†ì–´ë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤.

<br>

---

<br>

### **2ï¸âƒ£ ë°ì´í„° ìˆ˜ì§‘**

<br>

#### ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. í¬ë¡¤ë§ì„ í†µí•œ ëŒ“ê¸€ ë°ì´í„° ìˆ˜ì§‘

- í¬ë¡¤ë§ì„ í†µí•˜ì—¬ ëŒ“ê¸€ì„ ìˆ˜ì§‘í•˜ê³  ë¹„ì†ì–´ê°€ í¬í•¨ëœ ëŒ“ê¸€ê³¼ í¬í•¨ë˜ì§€ ì•Šì€ ëŒ“ê¸€ì˜ ë¹„ì¤‘ì„ ë§ì¶°ì£¼ê¸° ìœ„í•´ ì „ì²´ ëŒ“ê¸€ ë°ì´í„°ì˜ 45%ë¥¼ ì„ì˜ë¡œ ìš•ì„¤ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

    <details>
    <summary>í¬ë¡¤ë§ ë¡œì§</summary>

  ```
  if __name__ == '__main__':
      warnings.filterwarnings('ignore')

      if os.path.exists('comments.csv'):
          existing_df = pd.read_csv('comments.csv', encoding='utf-8-sig', index_col=0)
          comment_final = existing_df['Comment'].tolist()
      else:
          existing_df = pd.DataFrame()
          comment_final = []

      driver = webdriver.Chrome()
      driver.get("https://www.youtube.com/watch?v=t7w3k3pjZY4")
      driver.implicitly_wait(3)

      time.sleep(1.5)

      driver.execute_script("window.scrollTo(0, 800)")
      time.sleep(3)

      last_height = driver.execute_script("return document.documentElement.scrollHeight")

      while True:
          driver.execute_script("window.scrollTo(0, document.documentElement.scrollHeight);")
          time.sleep(2)

          new_height = driver.execute_script("return document.documentElement.scrollHeight")
          if new_height == last_height:
              break
          last_height = new_height

      time.sleep(1.5)

      html = driver.page_source
      soup = BeautifulSoup(html, 'html.parser')

      comment_list = soup.select("span.yt-core-attributed-string")

      for i in range(len(comment_list)):
          temp_comment = comment_list[i].text.replace('"', '')
          temp_comment = temp_comment.replace('\n', ' ')
          temp_comment = temp_comment.strip()
          comment_final.append(temp_comment)
      new_df = pd.DataFrame({'Comment': comment_final})

      combined_df = pd.concat([existing_df, new_df]).drop_duplicates().reset_index(drop=True)

      combined_df.to_csv('qweqwe.csv', index=True, encoding='utf-8-sig')

      driver.quit()
  ```

    </details>
    <br>
    <details>
    <summary>ì„ì˜ë¡œ ìš•ì„¤ì„ ì¶”ê°€í•˜ëŠ” ì½”ë“œ</summary>

  ```
  profanity_list = ['ìš•ì„¤ ë¦¬ìŠ¤íŠ¸']

  def add_random_profanity(comment):
      new_comment = ''
      for word in comment.split():
          new_comment += word + ' '
          if random.random() < 0.4:
              profanity = random.choice(profanity_list)
              if random.random() < 0.5:
                  new_comment += profanity + ' '
              else:
                  new_comment += profanity
      return new_comment.strip()

  co_df = pd.read_csv('comments.csv')

  co_df['Comment'] = co_df['Comment'].apply(add_random_profanity)
  ```

    </details>
    <br>
    <details>
    <summary>ì¶”ê°€í•œ ìš•ì„¤ì´ ìˆìœ¼ë©´ Target ì¹¼ëŸ¼ì— 1 ì—†ìœ¼ë©´ 0 ê°’ ë„£ì–´ì£¼ê¸°</summary>

  ```
  profanity_list = ['ìš•ì„¤ ë¦¬ìŠ¤íŠ¸']

  profanity_list = [word.replace(' ', '') for word in profanity_list]

  co_df['Profanity'] = co_df['Comment'].apply(lambda x: 1 if any(word in x for word in profanity_list) else 0)
  ```

    </details>

  <br>

2. ë°ì´í„°ì„¸íŠ¸ë¥¼ í†µí•œ ìˆ˜ì§‘

- ì§ì ‘ ëŒ“ê¸€ ë°ì´í„° ì„¸íŠ¸ë¥¼ ìˆ˜ì§‘
- ë°ì´í„° ì„¸íŠ¸ ê¹ƒí—ˆë¸Œ ì£¼ì†Œ: https://github.com/2runo/Curse-detection-data
- ëŒ“ê¸€ ë‚´ìš©ê³¼ íƒ€ê²Ÿì´ `|`ë¡œ êµ¬ë¶„ë˜ì–´ ìˆëŠ” ë°ì´í„° ì„¸íŠ¸ë¡œ read_csv ì‹œ `sep='|'`ì„ ì‚¬ìš©
  <details>
    <summary>Click to see full code</summary>

        import pandas as pd

        reply_df = pd.read_csv('./datasets/dataset.txt', sep='|')
        reply_df

  </details>

  <br>

3. ë‘ ë°ì´í„° ì„¸íŠ¸ í•©ì¹˜ê¸°

- ìˆ˜ì§‘í•œ ë‘ ë°ì´í„° ì„¸íŠ¸ë¥¼ í•©ì¹˜ê³  ê²°ê³¼ë¥¼ csvíŒŒì¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.

    <details>
    <summary>ë‘ ë°ì´í„° ì„¸íŠ¸ë¥¼ í•©ì¹˜ëŠ” ì½”ë“œ</summary>

  ```
      df_combined = pd.concat([co_df, bw_df], ignore_index=True)
  ```

    </details>
    <br>
    <details>
    <summary>ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ëŠ” ì½”ë“œ</summary>

  ```
      df_combined.to_csv('merge_comments_data.csv', index=False, encoding='utf-8-sig')
  ```

    </details>

  <br>

---

<br>

### **3ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬**

<br>

#### ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1.  ë‹¨ì–´ë³„ë¡œ ë¶„í• í•˜ì—¬ í•™ìŠµí•˜ëŠ” ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸°ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ë¶ˆìš©ì–´ë¥¼ ì œê±°í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ í•œê¸€, ì˜ì–´ì— ëŒ€í•œ ë¹„ì†ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ í•œê¸€, ì˜ì–´, ìˆ«ìë¥¼ ì œì™¸í•œ íŠ¹ìˆ˜ë¬¸ì, ì´ëª¨í‹°ì½˜, íƒ€ ì–¸ì–´ë¥¼ ì œê±°í•˜ì˜€ìŠµë‹ˆë‹¤.
    <details>
    <summary>í•œê¸€, ì˜ì–´, ìˆ«ìë¥¼ ì œì™¸í•œ ë¬¸ìë“¤ì„ ì œê±°í•˜ëŠ” ì½”ë“œ</summary>

    ```
        korean_stopwords = set([
            'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ë“¤', 'ì˜', 'ë¥¼', 'ì€', 'ëŠ”', 'ì—', 'ì™€', 'ê³¼', 'ë„', 'ìœ¼ë¡œ', 'ê¹Œì§€', 'ë¶€í„°', 'ë‹¤ì‹œ', 'ë²ˆ', 'ë§Œ', 'í• ', 'í•œë‹¤', 'ê·¸ë¦¬ê³ '
        ])

        # ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
        def preprocess_text(text):
            # íŠ¹ìˆ˜ ë¬¸ì ì œê±°
            text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s-]', '', text)
            text = re.sub(r'\s+', ' ', text).strip()
            # í˜•íƒœì†Œ ë¶„ì„
            words = text.split()
            # ë¶ˆìš©ì–´ ì œê±°
            text = ' '.join([word for word in words if word not in korean_stopwords])
            return text

        # ë°ì´í„° ì „ì²˜ë¦¬ ì ìš©
        reply_df['Comment'] = reply_df['Comment'].apply(preprocess_text)
        reply_df['Comment'].replace('', pd.NA, inplace=True)
        reply_df.dropna(subset=['Comment'], inplace=True)

    ```

    </details>
    <br>

2.  ì¤‘ë³µê³¼ nullì¸ ê°’ì„ í™•ì¸í•˜ê³  ì œê±°í•˜ì˜€ìŠµë‹ˆë‹¤.
    <details>
    <summary>ì¤‘ë³µê³¼ nullê°’ ì¡´ì¬ í™•ì¸ ë° ì œê±°í•˜ëŠ” ì½”ë“œ</summary>

    ```
    print(reply_df.duplicated().sum())
    reply_df.drop_duplicates(inplace=True)

    display(reply_df[reply_df['Comment'].isna()])
    reply_df = reply_df.dropna(subset=['Comment'])
    ```

    </details>

    <br>

3.  Target ë°ì´í„°ì˜ ë¹„ì¤‘ì„ ë§ì·„ìŠµë‹ˆë‹¤.
    <details>
    <summary>Target ë¹„ì¤‘ì„ í™•ì¸í•˜ê³  ì–¸ë” ìƒ˜í”Œë§í•˜ëŠ” ì½”ë“œ</summary>

        ```
            print(reply_df.Target.value_counts())

            profanity = reply_df[reply_df['Target'] == 1].sample(8151, random_state=124)
            normal = reply_df[reply_df['Target'] == 0]
            reply_df = pd.concat([profanity, normal]).reset_index(drop=True)
        ```

    </details>
    <br>

    <br>

---

<br>

### **4ï¸âƒ£ ëŒ“ê¸€ ì…ë ¥ì‹œ ìš•ì„¤ ë¶„ì„**

#### ëŒ“ê¸€ ì…ë ¥ì‹œ ìš•ì„¤ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. í™”ë©´ì—ì„œ ì…ë ¥ëœ ëŒ“ê¸€ì„ post-module.jsì˜ write í•¨ìˆ˜ì—ì„œ fatch ë¥¼ í†µí•´ post ë°©ì‹ìœ¼ë¡œ ì „ë‹¬
   <details>
   <summary>write í•¨ìˆ˜ ì½”ë“œ</summary>

   ```
       const write = async (reply) => {
           const response = await fetch("/post/replies/write/", {
               method: "POST",
               headers: {
                   'Content-Type': 'application/json;charset=utf-8',
                   'X-CSRFToken': csrf_token
               },
               body: JSON.stringify(reply)
           });
           return response.json()
       }
   ```

   </details>

<br>

2. view ì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ë¡œ ë¹„ì†ì–´ ê²€ì‚¬
   <details>
   <summary>ì „ë‹¬ ë°›ì€ ëŒ“ê¸€ ë‚´ìš© ë¹„ì†ì–´ ê²€ì‚¬ ì½”ë“œ</summary>

   ```
       class PostReplyWriteApi(APIView):
           @transaction.atomic
           def post(self, request):
               data = request.data
               post = Post.objects.filter(id=data['post_id']).values('member_id')

               new_sentence = [data['reply_content']]

               prediction = profanityDetectionPredict(new_sentence)
   ```

   </details>
   <br> 
   <details>
   <summary>ëª¨ë“ˆí™”ëœ ë¹„ì†ì–´ ê²€ì‚¬ ì½”ë“œ</summary>

   ```
       model_path = os.path.join(Path(__file__).resolve()\
           .parent, '../../ai/ai/commentai.pkl')
   ```


        def profanityDetectionPredict(new_sentence):
            loaded_model = joblib.load(model_path)

            prediction = loaded_model.predict(new_sentence)
            return prediction
    ```

    </details>

<br>

3. ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì–´ ìˆì„ ì•Šì„ ê²½ìš°(prediction[0]ê°€ 0ì¼ ê²½ìš°) í•´ë‹¹ ê²Œì‹œë¬¼ì— ëŒ“ê¸€ì´ ì¶”ê°€ë˜ëŠ” ì½”ë“œ
   <details>
   <summary>ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì½”ë“œ</summary>

   ```
       message = 'fails'
           if prediction[0] == 0:
               message = 'ok'

               data = {
                   'post_reply_content': new_sentence[0],
                   'post_id': data['post_id'],
                   'member_id': request.session.get('member')['id']
               }

               PostReply.objects.create(**data)
   ```

   </details>

<br>

4. ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì–´ ìˆì„ ê²½ìš° í•´ë‹¹ ëŒ“ê¸€ë¡œ ëª¨ë¸ì˜ ì¶”ê°€í•™ìŠµì„ ì§„í–‰í•˜ê³  í›ˆë ¨ ì „ìš© í…Œì´ë¸”ì— ì¶”ê°€í•˜ëŠ” ì½”ë“œ
   <details>
   <summary>ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì–´ìˆì„ ê²½ìš° ì¶”ê°€í•™ìŠµ ì‹œí‚¤ëŠ” ì½”ë“œ</summary>

   ```
           else:
               data = {
                   'comment': new_sentence[0],
                   'target': 1,
               }

               profanityDetectionModel(new_sentence)

               AiPostReply.objects.create(**data)

           return Response(message)
   ```

   </details>
   <br>    
   <details>
   <summary>ëª¨ë“ˆí™”ëœ ì¶”ê°€í•™ìŠµ ì‹œí‚¤ëŠ” ì½”ë“œ</summary>

   ```
       model_path = os.path.join(Path(__file__).resolve()\
           .parent, '../../ai/ai/commentai.pkl')

       def profanityDetectionModel(new_sentence):
           loaded_model = joblib.load(model_path)
           transformed_X_train = loaded_model.named_steps['count_vectorizer']\
               .transform(new_sentence)
           loaded_model.named_steps['multinomial_NB']\
               .partial_fit(transformed_X_train, [1])
           joblib.dump(loaded_model, model_path)
   ```

   </details>

<br>

---

<br>

### **5ï¸âƒ£ ë¬¸ì œ ëŒ“ê¸€ ì‹ ê³  ì‹œ ì‹¤ì‹œê°„ í•™ìŠµ**

#### ëŒ“ê¸€ ì‹ ê³ ì‹œ ìš•ì„¤ ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. ì‹ ê³ ëœ ëŒ“ê¸€ì„ ì²˜ë¦¬í•˜ëŠ” viewì—ì„œ ì‹ ê³ ë°›ì€ ëŒ“ê¸€ì„ ì¼ë°˜ ê²Œì‹œë¬¼ ëŒ“ê¸€ ì‹ ê³  í…Œì´ë¸”ì— ì¶”ê°€
   <details>
   <summary>ì¼ë°˜ ê²Œì‹œë¬¼ ëŒ“ê¸€ ì‹ ê³  í…Œì´ë¸”ì— ì¶”ê°€ ì½”ë“œ</summary>

   ```
       class PostReplyReportView(View):
           def post(self, request):
               data = request.POST
               member = request.session.get('member')['id']
               member_id = member.get('id')
               post_id = request.GET['id']
               reply_id = data['reply-report-reply-id']

               datas = {
                   'member_id': member_id,
                   'post_reply_id': reply_id,
                   'report_content': data['reply-report-content']
               }

               PostReplyReport.object.create(**datas)

               return redirect(f'/post/detail/?id={post_id}')
   ```

   </details>

<br>

2. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ì‹ ê³ ëœ ëŒ“ê¸€ì„ í™•ì¸í•˜ê³  ì‹ ê³ ë‹¹í•œ ëŒ“ê¸€ì„ ì‚­ì œ ì²˜ë¦¬í•˜ëŠ” viewì—ì„œ ì‚­ì œí•˜ê¸°ì „ í•´ë‹¹ ìš•ì„¤ ëŒ“ê¸€ë¡œ ëª¨ë¸ì„ ì¶”ê°€í•™ìŠµì„ ì§„í–‰, ì¼ë°˜ ëŒ“ê¸€ í…Œì´ë¸”ì—ì„œ ì‚­ì œí•˜ê³  ëª¨ë¸ í›ˆë ¨ í…Œì´ë¸”ì— ì¶”ê°€
   <details>
   <summary>ì‚­ì œí•˜ê¸°ì „ í•´ë‹¹ ìš•ì„¤ ëŒ“ê¸€ë¡œ ëª¨ë¸ì„ ì¶”ê°€í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ì½”ë“œ</summary>

   ```
       def delete(self, request, report_ids):
           report_ids = report_ids.split(',')

           for report_id in report_ids:
               if report_id != '':
                   post_report_reply = PostReplyReport.object.filter(id=report_id)\
                       .values().first()
                   report_reply_id = post_report_reply.get('post_reply_id')
                   post_reply = PostReply.objects.filter(id=report_reply_id)\
                       .values().first()

                   new_sentence = [post_reply['post_reply_content']]
                   profanityDetectionModel(new_sentence)

   ```

   </details>
   <br> 
   <details>
   <summary>ì¼ë°˜ ëŒ“ê¸€ í…Œì´ë¸”ì—ì„œ ì‚­ì œí•˜ê³  ëª¨ë¸ í›ˆë ¨ í…Œì´ë¸”ì— ì¶”ê°€í•˜ëŠ” ì½”ë“œ</summary>

   ```
                   data = {
                       'comment': new_sentence[0],
                       'target': 1,
                   }
                   AiPostReply.objects.create(**data)

                   PostReplyReport.object.get(id=report_id).delete()
                   PostReply.objects.get(id=report_reply_id).delete()
   ```

   </details>

<br>

---

<br>

### **6ï¸âƒ£ ìš•ì„¤ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ íë¦„**

<br>

#### ìš•ì„¤ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ì˜ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. í™”ë©´ì—ì„œ ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ” ëŒ“ê¸€ ì…ë ¥

   > ![image](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/e971451c-f718-4bcf-9b16-86e6b6713036)

2) ì…ë ¥ í´ë¦­ì‹œ post-module.jsì´ writeë¥¼ í†µí•˜ì—¬ í•´ë‹¹ ì •ë³´ post ë°©ì‹ìœ¼ë¡œ viewì— ì „ë‹¬
3) viewì—ì„œ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì„ í†µí•´ ë¹„ì†ì–´ í¬í•¨ ìœ ë¬´ë¥¼ ê²€ì‚¬í•˜ê³  ê²°ê³¼ë¥¼ return (ë¹„ì†ì–´ê°€ í¬í•¨ëœ ê²½ìš° ì¶”ê°€í•™ìŠµí›„ return)
4) returnëœ ê°’ì„ post-moduleì—ì„œ writeí•¨ìˆ˜ì˜ fetchë¥¼ í†µí•´ responseë¡œ return
5) returnìœ¼ë¡œ ì „ë‹¬ë°›ì€ response ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ 'ë¹„ì†ì–´ê°€ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤' ë¬¸êµ¬ í™”ë©´ì— ì¶œë ¥

   > ![image-3](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/24face29-414c-4474-bd27-db0fbbffaac3)

6. ë¹„ì†ì–´ê°€ í¬í•¨í•˜ì—¬ ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì‚¬ìš©ìëŠ” ì •ìƒì ì¸ ëŒ“ê¸€ì„ ì…ë ¥í•˜ê²Œ ë¨
7. ë¹„ì†ì–´ë¥¼ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì´ ê°ì§€í•˜ì§€ ëª»í•  ê²½ìš° ì‹ ê³  ê¸°ëŠ¥ì„ í†µí•´ ê´€ë¦¬ìì—ê²Œ ë¹„ì†ì–´ ëŒ“ê¸€ì´ ìˆìŒì„ ì•Œë¦¼

   > ![image-3](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/7314b731-49b4-480c-8b46-75560aaaaedb)

8. ê´€ë¦¬ìê°€ í•´ë‹¹ ì‹ ê³ ë¥¼ í™•ì¸í•˜ê³  ë¹„ì†ì–´ ëŒ“ê¸€ì„ ì‚­ì œì‹œ ì¶”ê°€í•™ìŠµ ì§„í–‰í›„ ì‚­ì œì²˜ë¦¬ (ëª¨ë¸ í›ˆë ¨ í…Œì´ë¸”ì—ëŠ” ì¶”ê°€)

   > ![image-3](https://github.com/baek-si-hyun/selleaf-server/assets/107901109/74dd3564-d68b-42ff-90cd-d2595dd3f2df)

9. ê°ì§€í•˜ì§€ ëª»í•œ ë¹„ì†ì–´ë¥¼ í•™ìŠµí•¨ìœ¼ë¡œ ëª¨ë¸ì˜ ë¹„ì†ì–´ ê°ì§€ ëŠ¥ë ¥ í–¥ìƒ

---

<br>

### **7ï¸âƒ£ ê²°ê³¼**

<br>

> #### ğŸš© ë¹„ì†ì–´ ëŒ“ê¸€
>
> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/24face29-414c-4474-bd27-db0fbbffaac3" width="600px">

> #### ğŸš© ë¹„ì†ì–´ ëŒ“ê¸€ ì‹ ê³ 
>
> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/7314b731-49b4-480c-8b46-75560aaaaedb" width="300px">

> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/06149d04-cc85-4d48-8a88-06881b3f0b63" width="300px">
> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/74dd3564-d68b-42ff-90cd-d2595dd3f2df" width="500px">
> <img src="https://github.com/baek-si-hyun/selleaf-server/assets/107901109/d98c7474-1837-418a-af16-d2814ab48d18" width="500px">

---

<br>

### **8ï¸âƒ£ íŠ¸ëŸ¬ë¸” ìŠˆíŒ…**

<br>
<br>

#### 1. ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ì´ ì…ë ¥ ë°›ì€ ë‹¨ì–´ì™€ ìƒê´€ì—†ì´ ëª¨ë‘ ë¹„ì†ì–´ë¼ê³  ì˜ˆì¸¡

â— ë¬¸ì œ

- ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ ì ìš©í•˜ì—¬ ë¹„ì†ì–´ ëŒ“ê¸€ ì§ì ‘ ì…ë ¥í•´ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê³¼ì •ì—ì„œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì´ ì…ë ¥ ë°›ì€ ë‹¨ì–´ì™€ ìƒê´€ì—†ì´ ëª¨ë‘ ë¹„ì†ì–´ê°€ í¬í•¨ ë˜ì–´ìˆë‹¤ê³  ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œ ë°œìƒ
  > <img src="https://github.com/baek-si-hyun/django_with_ai/assets/107901109/8d9d0f88-77bf-4779-80d5-af1bb1a0e82e" width="500px">
  >
  > <small>1ì€ ë¹„ì†ì–´ê°€ í¬í•¨ ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.</small>
  >
  > <img src="https://github.com/baek-si-hyun/django_with_ai/assets/107901109/2677ef68-50e5-4f16-9b7b-35ac3c015a0f" width="100px">

<br>

â“ ì›ì¸

- <code>.fit</code> ì „ì²´ ë°ì´í„°ë¥¼ í•œë²ˆì— í•™ìŠµ ì‹œí‚¤ëŠ” ë©”ì„œë“œì´ë‹¤. <code>.fit</code>ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ ì‚¬ì „ í›ˆë ¨ì„ ì§„í–‰í•œ ìƒíƒœì´ë‹¤.
- í™”ë©´ì—ì„œ ì „ë‹¬ë°›ì€ ë¬¸ì¥ì„ ì¶”ê°€í•™ìŠµ ì‹œì¼œì•¼ í•˜ëŠ”ë° <code>.fit</code>ì´ë¼ëŠ” ë™ì¼í•œ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ì‚¬ì „ í›ˆë ¨ì„ ë°›ì€ ëª¨ë¸ì— ì¶”ê°€í•™ìŠµì´ ì•„ë‹Œ ë®ì–´ì“°ê¸°ê°€ ì§„í–‰ë˜ì—ˆë‹¤.
- ì´ë¡œ ì¸í•´ ë°ì´í„°ê°€ í•˜ë‚˜ì¸ í›ˆë ¨ëª¨ë¸ì´ ë˜ì–´ ìœ„ì™€ê°™ì€ ë¬¸ì œê°€ ë°œìƒ ë˜ì—ˆë‹¤.

![p_fit](https://github.com/baek-si-hyun/django_with_ai/assets/107901109/58f89411-f224-4e58-b817-24a0ba66a5de)

- í™”ë©´ì—ì„œ ì „ë‹¬ ë°›ì€ ë¬¸ì¥ í•˜ë‚˜ë¡œ ì´ë¯¸ í›ˆë ¨ëœ ëª¨ë¸ì— ì „ì²´ ë°ì´í„° í•™ìŠµì„ ì§„í–‰ ì‹œì¼°ë‹¤.
- ê¸°ì¡´ì— ì‚¬ì „ í›ˆë ¨ë°›ì€ ëª¨ë¸ì˜ ë°ì´í„°ëŠ” ë‹¤ ì‚¬ë¼ì§€ê³  ì „ë‹¬ ë°›ì€ ë¬¸ì¥ ë°ì´í„° í•˜ë‚˜ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì´ ë˜ì—ˆë‹¤.

<br>

âœ” í•´ê²°

- ì „ì²´ ë°ì´í„°ë¥¼ í•™ìŠµ ì‹œí‚¤ëŠ” <code>.fit</code>ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê¸°ì¡´ì— í›ˆë ¨ë˜ì–´ ìˆëŠ” ëª¨ë¸ì— ì¶”ê°€ë¡œ í•™ìŠµì„ ì§„í–‰ì‹œí‚¤ëŠ” <code>.partial_fit</code>ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ê²°í•˜ì˜€ë‹¤.
  >
  > <img src="https://github.com/baek-si-hyun/django_with_ai/assets/107901109/3e125e8c-f834-49d4-96d1-bba752a4640e" width="500px">
  > <br><br>
  > <img src="https://github.com/baek-si-hyun/django_with_ai/assets/107901109/8d9d0f88-77bf-4779-80d5-af1bb1a0e82e" width="500px">
  > 
  > <small>0ì€ ë¹„ì†ì–´ê°€ í¬í•¨ ë˜ì–´ìˆì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.</small>
  >
  > <img src="https://github.com/baek-si-hyun/django_with_ai/assets/107901109/710c12e2-2bda-418f-9cfa-aafd2f2ce09c" width="100px">

<br>
<br>

### 2. ë„ˆë¬´ ë‚®ì€ ì •í™•ë„ë¡œ ì¸í•œ ë¹„ì†ì–´ ì˜ˆì¸¡ ë¬´ì˜ë¯¸

â— ë¬¸ì œ

- ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ì˜ í‰ê°€ ì§€í‘œê°€ ì •í™•ë„, ì •ë°€ë„ ì¬í˜„ìœ¨, f1 score ëª¨ë‘ 0.60 ~ 0.63 ìœ¼ë¡œ ë‚®ì€ ìˆ˜ì¹˜ë¥¼ ë³´ì—¬ì£¼ì—ˆë‹¤.
- ë¶ˆìš©ì–´('ì˜', 'ë¥¼', 'ì€', 'ëŠ”', 'ì—', ë“±) ì˜ë¯¸ë¥¼ ì „ë‹¬í•˜ì§€ ì•ŠëŠ” ìš©ì–´ë“¤ì„ ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì œê±° í•˜ì˜€ëŠ”ë°ë„ ìˆ˜ì¹˜ì— ë³€í™”ê°€ ì—†ì—ˆë‹¤.

<br>

â“ ì›ì¸

- íƒ€ íŒ€ë“¤ì˜ ëŒ“ê¸€ ë¹„ì†ì–´ ê°ì§€ ì‹œìŠ¤í…œ ë‹´ë‹¹ìë“¤ê³¼ ì†Œí†µí•œ ê²°ê³¼ ë°ì´í„° ì„¸íŠ¸ ìˆ˜ê°€ 5000ê°œë¡œ ëª¨ë¸ì´ í•™ìŠµí•˜ê¸°ì—ëŠ” ì ë‹¤ê³  íŒë‹¨í–ˆë‹¤.

<br>

âœ” í•´ê²°

- ì„œë¡œì˜ ë°ì´í„° ì„¸íŠ¸ë¥¼ í†µí•©í•˜ê³  ì¶”ê°€ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ 10000ê°œê°€ ë„˜ëŠ” ë°ì´í„° ì„¸íŠ¸ë¥¼ ì œì‘í•˜ì˜€ë‹¤.
  > <img src="https://github.com/baek-si-hyun/django_with_ai/assets/107901109/77af3f38-231d-445d-a22e-e503c7f134c9" width="500px" >

<br>

- í•œêµ­ì–´, ì˜ì–´, ìˆ«ìë¥¼ ì œì™¸í•œ ë¬¸ìë“¤ì€ ë¹ˆë¬¸ìì—´ë¡œ ëŒ€ì²´ë¥¼ í•˜ëŠ” ì „ì²˜ë¦¬ ê³¼ì •ì„ ì¶”ê°€í•˜ì˜€ë‹¤.
  >
  > <img src="https://github.com/baek-si-hyun/django_with_ai/assets/107901109/413f2b08-454e-464c-9b57-8856657ceef7" width="500px" >

<br>

- ë°ì´í„°ì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ê³ , ì „ì²˜ë¦¬ ê³¼ì •ì„ í†µí•´ ëª©í‘œ ìˆ˜ì¹˜ì˜€ë˜ 0.7ì„ ë„˜ê¸°ë©° ë¬¸ì œë¥¼ í•´ê²°í•˜ì˜€ë‹¤.
  > <img src="https://github.com/baek-si-hyun/django_with_ai/assets/107901109/af3e1ac9-8dbf-411e-9250-adc160c6abd3" width="700px" >

<br>

### **9ï¸âƒ£ ëŠë‚€ì **

- ì§ì ‘ ìˆ˜ì§‘í•œ ë°ì´í„°ì˜€ê¸°ì— ë…¸ì´ì¦ˆê°€ ë§ì•˜ê³  ì´ëŠ” í›ˆë ¨ ëª¨ë¸ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¼ì³ í‰ê°€ì§€í‘œì˜ ìˆ˜ì¹˜ë¥¼ ë†’ì´ëŠ”ë° ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëŒ“ê¸€ ì‹œìŠ¤í…œ ë‹´ë‹¹ìì™€ í˜‘ì—…í•˜ë©° ìµœì ì˜ ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ì™€ ëª¨ë¸ íŠœë‹ì„ ê²½í—˜í•˜ë©° 
ì˜ ì •ì œëœ ë°ì´í„°ì˜ ì¤‘ìš”ì„±ì„ ëŠê¼ˆê³  ë˜í•œ ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œì˜ ì„¸ì‹¬í•œ ì ‘ê·¼ì´ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ ê¹¨ë‹«ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

- ì¸ê³µì§€ëŠ¥ì„ ì§ì—… ìƒìš©í™”í•´ë³´ë©´ì„œ ì¸ê³µì§€ëŠ¥ì˜ ì´ì ë“¤ì„ ëª¸ìœ¼ë¡œ ëŠë‚„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì œê°€ ë§¡ì€ ëŒ“ê¸€ ê´€ë¦¬ëŠ” ì „ë¶€ ì‚¬ëŒì´ ì§ì ‘ í•œë‹¤ë©´ ë§ì€ ì¸ë ¥ê³¼ ë¹„ìš©ì´ ë‚­ë¹„ë˜ëŠ” íŒŒíŠ¸ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ AIê°€ ëŒ€ë¶€ë¶„ ì´ë¥¼ ëŒ€ì‹ í•˜ê²Œ ë˜ë©´ì„œ ê¸°ì—… ì…ì¥ì—ì„œ ì™œ AIë¥¼ ë„ì…í•˜ë ¤ëŠ”ì§€ ëª¸ìœ¼ë¡œ ëŠë‚„ ìˆ˜ ìˆì—ˆê³ , ì‹ ê³  ê¸°ëŠ¥ì„ í†µí•´ ëª¨ë¸ì— ì¶”ê°€ í•™ìŠµì„ ì§„í–‰í•˜ë©´ í• ìˆ˜ë¡ ë”ìš± ì •êµí•´ì§€ëŠ” ì¸ê³µì§€ëŠ¥ì„ ë³´ë©°, AIì˜ í•™ìŠµ ëŠ¥ë ¥ê³¼ ì ì‘ë ¥ì´ ì–¼ë§ˆë‚˜ ë›°ì–´ë‚œì§€ ê¹¨ë‹«ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.